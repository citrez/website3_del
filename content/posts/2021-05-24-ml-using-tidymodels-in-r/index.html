---
title: ML using Tidymodels in R
author: Ezra Citron
date: '2021-05-24'
slug: []
categories: ['Machine Learing','tidymodels']
tags: []
description: ~
#featured_image: "/post_tidymodels/tidymodels.jpeg"
--- 



<p>For a long while Machine Learning in R has seemed like a poor substitute for python’s scikit-learn. R’s strengths have historically been in data manipulation and statistical analysis but has lagged behind python in terms of having a consistent and easily-useable API for machine learning…
This is where the <code>tidymodels</code> framework comes in. The aim of tidymodels is to mimic the consistency and simplicity of the tidyverse for machine learning, so that you can run your entire pipeline without leaving the comfort of Rstudio.
At a very high level, this is what the workflow should look like.</p>
<div class="figure">
<img src="/post_tidymodels/ds_flow.png" alt="" />
<p class="caption">data science workflow</p>
</div>
<p>Lets meet the packages.</p>
<pre class="r"><code>library(tidyverse)
library(tidymodels)</code></pre>
<p>There are few sub-packages that you should become familiar with in the <code>tidymodels</code> eco system. Much like the tidyverse has dplyr, purrr, readr, stringr…etc tidymodels has rsamples, recipies, parsnip, tune… etc.</p>
<ul>
<li><code>rsample</code> - Different types of re-samples</li>
<li><code>recipes</code> - Transformations for model data pre-processing</li>
<li><code>parnip</code> - A common interface for model creation</li>
<li><code>yardstick</code> - Measure model performance</li>
</ul>
<p>I have heard the Rstudio community refer to <a href="https://github.com/r-lib/devtools#conscious-uncoupling">‘consious uncoupling’</a> when talking about splitting packages up into smaller onces which do a specific job. ‘consious uncoupling’ sounds too similar to something out of a gwenith paltrow book for me to feel fully comfortable with, but i think the idea makes sense.</p>
<p><img src="/post_tidymodels/tidymodels_flow.png" /></p>
<p>This walkthrough is inspired by the amazing work of julia silge from Rstudio, one of the creators of tidymodels. If you haven’t already, I highly recommend you check out her blog for more info. I was also heavily guided by <a href="https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/">this</a> tidymodels blogpost - well worth checking out.</p>
<p>I’ll be using <code>iris</code> dataset that comes pre-loaded with tidyverse, so that we can focus on the methods rather than the data and so that no one has an excuse not to follow along. In future blogs, i’ll explore other data sources.</p>
<pre class="r"><code>iris %&gt;% head(n = 5)</code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa</code></pre>
<p>Alight, enough talk, lets dive in.</p>
<pre class="r"><code>library(rsample)
iris_split &lt;- rsample::initial_split(iris,prop = 0.7,strata = Species)
iris_split</code></pre>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;105/45/150&gt;</code></pre>
<p>We use rsample to split into training and testing set, much like ‘train_test_split’ from sklearn.model_selection in python. This returns a split object, which prints the number of rows in the train, test set and overall rows. The training and testing data can be accessed pretty easily as follows</p>
<pre class="r"><code>iris_train &lt;- training(iris_split) 
iris_test &lt;- testing(iris_split)
iris_train %&gt;% head(n = 5) </code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa</code></pre>
<p>The <code>recipies</code> package will give us the tools we need for pre-processing our iris data.
We need to tell the recipie the predictor and predicted variable, we give it this information in formula form i.e <code>Species ~ .</code> where . is a shorthand for ‘all other variables’.</p>
<p>The we pipe this reicpie into various steps, which do all sorts of best-pratice ML pre-processing steps for you. Some examples include:</p>
<ul>
<li>step_zv() - removes vaiables with zero varience</li>
<li>step_lag() - creates a lagged variable</li>
<li>step_center() - centers variable to have mean of zero</li>
<li>step_other() - pool infrequent categorical variables into “Other”</li>
<li>step_scale() - creates a standard deviation of one</li>
<li>step_corr() - removes highly correlated variables</li>
<li>step_dummy() - creates dummys (or one-hot-encoding) from categorical variables</li>
</ul>
<p>and many, many <a href="https://recipes.tidymodels.org/reference/index.html">others</a>…</p>
<p>I find, not only are these convenient for data pre-processing, but they help enforce best pratice, and also encorage you to tune these pre-processing steps as part of your overall model tuning. Something which I feel is underrated and can hugely improve model accuracy.</p>
<pre class="r"><code>iris_recipe &lt;- iris_train %&gt;% 
  recipe(Species ~ . ) %&gt;% 
  step_corr(all_predictors(),threshold = 0.9) %&gt;%
  step_center(all_predictors(), -all_outcomes()) %&gt;%
  step_scale(all_predictors(), -all_outcomes())

iris_recipe_prepped &lt;-  prep(iris_recipe)</code></pre>
<p>The unprepper recipie is the general blueprint for preprocessing. ‘prepping’ it, preforms the preprocessing with the training set. So for example, It will use the trianing set to decide which variables in needs to drop through the <code>step_corr()</code> step. See the differnce in outputs between <code>iris_recipe</code> and <code>iris_recipe_prepped</code> for the general and specific case.</p>
<p><em>Remeber</em> the test set must be transformed using the exact same pre-processing ‘learned’ from the training set. I.e if the step_corr() removed <code>Petal.Length</code> column from the data, this must be removed from test data, even if the correlation did not meet the threshold in the test set. Another example, the training set was centered and scaled by subtracting the mean of each column and deivding by the standard deviation. The <strong>test set</strong> is scaled using the <strong>traiing set</strong> mean and standard deviation.</p>
<p>So we <code>bake()</code> our test set using the recipe prepped on the traiing set</p>
<pre class="r"><code>iris_test_baked &lt;- iris_recipe_prepped %&gt;%
  bake(iris_test) </code></pre>
<pre class="r"><code>iris_train_juiced&lt;- juice(iris_recipe_prepped)</code></pre>
<div id="time-to-actually-train-a-model" class="section level3">
<h3>Time to actually train a model</h3>
<p>There are often many different packages that fit the same type of model, with each one having slightly different interface and terminology. The beauty of tidymodels is that it provides a consistent set of functions and augments and then allows you to pick which package to use ‘behind the scenes’.</p>
<p>To make the concrete, training a random forest can be done with <code>ranger</code> and <code>randomForst</code> packages.
To set the hyperparameter for the number of trees you want to build ranger uses <code>nu.trees</code> randomForest uses <code>ntree</code>. Tidymodels eliminates this unnecessary complication, making it much simpler to switch between models.</p>
<pre class="r"><code>iris_rf &lt;- rand_forest(trees = 150, mode = &#39;classification&#39;) %&gt;% 
  set_engine(&#39;randomForest&#39;) %&gt;% 
  fit(Species~., data = iris_train_juiced)</code></pre>
<p>the <code>rand_forest</code> function generates your specification for the model, usingthings like:
- trees - The number of trees contained in the ensemble.
- min_n - The minimum number of data points in a node that are required for the node to be split further.
This is quite similar to the RandomForestClassifier class from the sklearn.ensemble module.</p>
<p>set_engine allows you to seemlessly move between the package used to fit the model, we could have written
<code>set_engine("ranger")</code> instead.</p>
<p><code>fit</code> fits the model to the training data, with the formula telling the model which variables are predictors and predicted.</p>
<p>DONE!</p>
<p>To summarise, we split into a training and test set using rsamle. We preprocessed our data using recipies and then trained a model using parsnip. Now lets evaluate how well our model has done using yardstick.</p>
<p>First, lets use our model to predict the Species on our test set.</p>
<pre class="r"><code>predict(iris_rf,iris_test_baked) %&gt;% head(n = 5)</code></pre>
<pre><code>## # A tibble: 5 x 1
##   .pred_class
##   &lt;fct&gt;      
## 1 setosa     
## 2 setosa     
## 3 setosa     
## 4 setosa     
## 5 setosa</code></pre>
<p>Another big benefit tidymodels ecosystem is that its works so smoothly with the tidyverse.
The output of the <code>predict()</code> function is a tidy tibble.</p>
<p>We can now easily stick this next to our test set to see where the predictions were right and wrong</p>
<pre class="r"><code> bind_cols(iris_test,predict(iris_rf,iris_test_baked) )  %&gt;% head(n = 5)</code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .pred_class
## 1          5.4         3.9          1.7         0.4  setosa      setosa
## 2          4.6         3.4          1.4         0.3  setosa      setosa
## 3          4.8         3.0          1.4         0.1  setosa      setosa
## 4          5.7         4.4          1.5         0.4  setosa      setosa
## 5          5.1         3.5          1.4         0.3  setosa      setosa</code></pre>
<p>we can pipe this into metrics to get the overall accuracy which is #correctly classified/#total</p>
<pre class="r"><code> bind_cols(iris_test,predict(iris_rf,iris_test_baked) ) %&gt;%
  metrics(truth = Species, estimate = .pred_class) %&gt;% head(n = 5)</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy multiclass     0.978
## 2 kap      multiclass     0.967</code></pre>
<p>You can also get back the predicted probability for each class</p>
<pre class="r"><code> bind_cols(iris_test,predict(iris_rf,iris_test_baked,type = &#39;prob&#39;) ) %&gt;% head(n = 5)</code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species .pred_setosa
## 1          5.4         3.9          1.7         0.4  setosa    1.0000000
## 2          4.6         3.4          1.4         0.3  setosa    1.0000000
## 3          4.8         3.0          1.4         0.1  setosa    0.9466667
## 4          5.7         4.4          1.5         0.4  setosa    0.9533333
## 5          5.1         3.5          1.4         0.3  setosa    1.0000000
##   .pred_versicolor .pred_virginica
## 1       0.00000000      0.00000000
## 2       0.00000000      0.00000000
## 3       0.03333333      0.02000000
## 4       0.03333333      0.01333333
## 5       0.00000000      0.00000000</code></pre>
<pre class="r"><code> bind_cols(iris_test,predict(iris_rf,iris_test_baked,type = &#39;prob&#39;) ) %&gt;%
  roc_curve(Species, .pred_setosa:.pred_virginica) %&gt;%
  ggplot2::autoplot()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Which you need to build an <a href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5">ROC_AUC curve</a> which plots the TPR and FNR for different thresholds. <img src="/post_tidymodels/confusionmatrix.jpeg" style="width:50.0%" alt="confusion matrix" /></p>
<p>Thanks for sticking around, I hope I’ve convinced you that tidymodels is a reasonable substitution for other ML packages and can help simplify you workflow. Stay tuned for more tidymodelling blogs in future.</p>
</div>
